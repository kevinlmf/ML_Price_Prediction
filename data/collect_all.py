#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…¨è‡ªåŠ¨æ•°æ®æ”¶é›†è„šæœ¬
æ”¶é›†ä»·æ ¼æ•°æ® -> æ”¶é›†æ–°é—»æ•°æ® -> æ•°æ®å¯¹é½ -> ç”ŸæˆLSTMè®­ç»ƒåºåˆ—
"""

import os
import sys
import argparse
from datetime import datetime, timedelta, timezone
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥å…¶ä»–æ¨¡å—
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

from news_collector import NewsCollector
from price_collector import PriceCollector  
from data_aligner import DataAligner


def main():
    parser = argparse.ArgumentParser(description="ä¸€é”®æ”¶é›†æ‰€æœ‰æ•°æ®å¹¶å¯¹é½")
    parser.add_argument("--symbols", type=str, default="AAPL,MSFT,GOOGL,TSLA,NVDA", 
                        help="è‚¡ç¥¨ä»£ç ï¼Œé€—å·åˆ†éš”")
    parser.add_argument("--days_back", type=int, default=365, 
                        help="æ”¶é›†å¤šå°‘å¤©çš„æ•°æ®")
    parser.add_argument("--news_days", type=int, default=30,
                        help="æ–°é—»æ•°æ®å¤©æ•°")
    parser.add_argument("--sequence_length", type=int, default=30,
                        help="LSTMåºåˆ—é•¿åº¦")
    parser.add_argument("--target", type=str, default="Price_Direction",
                        help="é¢„æµ‹ç›®æ ‡åˆ—")
    parser.add_argument("--output_dir", type=str, default="./",
                        help="è¾“å‡ºç›®å½•")
    parser.add_argument("--newsapi_key", type=str, default="",
                        help="NewsAPIå¯†é’¥ï¼ˆå¯é€‰ï¼‰")
    
    args = parser.parse_args()
    
    # è§£æè‚¡ç¥¨ä»£ç 
    symbols = [s.strip() for s in args.symbols.split(",") if s.strip()]
    
    print("=" * 60)
    print("ğŸš€ å¼€å§‹å…¨è‡ªåŠ¨æ•°æ®æ”¶é›†æµç¨‹")
    print(f"ğŸ“Š è‚¡ç¥¨ä»£ç : {symbols}")
    print(f"ğŸ“… æ•°æ®å¤©æ•°: {args.days_back} å¤©")
    print(f"ğŸ“° æ–°é—»å¤©æ•°: {args.news_days} å¤©") 
    print("=" * 60)
    
    # è®¡ç®—æ—¥æœŸèŒƒå›´
    end_date = datetime.now(tz=timezone.utc).date()
    start_date = end_date - timedelta(days=args.days_back)
    
    try:
        # æ­¥éª¤1: æ”¶é›†ä»·æ ¼æ•°æ®
        print("\nğŸ“ˆ æ­¥éª¤1: æ”¶é›†ä»·æ ¼æ•°æ®...")
        price_collector = PriceCollector()
        stock_data = price_collector.get_stock_data(symbols, str(start_date), str(end_date))
        
        if not stock_data:
            print("âŒ æœªèƒ½æ”¶é›†åˆ°ä»·æ ¼æ•°æ®ï¼Œé€€å‡º")
            return
            
        price_collector.save_data(stock_data, output_dir=args.output_dir)
        print(f"âœ… ä»·æ ¼æ•°æ®æ”¶é›†å®Œæˆï¼Œå…± {sum(len(df) for df in stock_data.values())} æ¡è®°å½•")
        
        # æ­¥éª¤2: æ”¶é›†æ–°é—»æ•°æ®
        print("\nğŸ“° æ­¥éª¤2: æ”¶é›†æ–°é—»æ•°æ®...")
        news_collector = NewsCollector(newsapi_key=args.newsapi_key or None)
        news_df = news_collector.get_financial_news(symbols, days_back=args.news_days, sleep_sec=0.5)
        
        if news_df.empty:
            print("âš ï¸ æœªæ”¶é›†åˆ°æ–°é—»æ•°æ®ï¼Œä»…ä½¿ç”¨ä»·æ ¼æ•°æ®")
        else:
            print(f"ğŸ“„ åŸå§‹æ–°é—»æ•°æ®: {len(news_df)} æ¡")
            
        # æ¸…ç†æ–°é—»æ•°æ®
        news_df = news_collector.clean_news_data(news_df)
        
        # ä¿å­˜æ–°é—»æ•°æ®
        news_output = os.path.join(args.output_dir, "news_data.csv")
        news_collector.save_news_data(news_df, filename=news_output)
        print(f"âœ… æ–°é—»æ•°æ®å¤„ç†å®Œæˆï¼Œæ¸…ç†å {len(news_df)} æ¡è®°å½•")
        
        # æ­¥éª¤3: æ•°æ®å¯¹é½å’Œç‰¹å¾å·¥ç¨‹
        print("\nğŸ”— æ­¥éª¤3: æ•°æ®å¯¹é½å’Œç‰¹å¾å·¥ç¨‹...")
        aligner = DataAligner()
        
        price_path = os.path.join(args.output_dir, "prices.csv")
        news_path = news_output
        
        # è¿è¡Œå®Œæ•´å¯¹é½æµç¨‹
        aligned_df, X, y = aligner.run_full_alignment(
            price_path=price_path,
            news_path=news_path,
            sequence_length=args.sequence_length,
            target_col=args.target
        )
        
        if aligned_df.empty:
            print("âŒ æ•°æ®å¯¹é½å¤±è´¥")
            return
            
        print(f"âœ… æ•°æ®å¯¹é½å®Œæˆï¼Œåˆå¹¶æ•°æ®: {aligned_df.shape}")
        
        # æ­¥éª¤4: æ˜¾ç¤ºç»“æœæ‘˜è¦
        print("\n" + "=" * 60)
        print("ğŸ‰ æ•°æ®æ”¶é›†æµç¨‹å®Œæˆï¼")
        print("=" * 60)
        
        # æ–‡ä»¶æ¸…å•
        files_created = []
        for symbol in symbols:
            symbol_file = os.path.join(args.output_dir, f"{symbol}_price_data.csv")
            if os.path.exists(symbol_file):
                files_created.append(f"{symbol}_price_data.csv")
                
        files_created.extend([
            "prices.csv (åˆå¹¶çš„ä»·æ ¼æ•°æ®)",
            "news_data.csv (æ–°é—»æ•°æ®)", 
            "aligned_data.csv (å¯¹é½åçš„æ•°æ®)"
        ])
        
        if len(X) > 0:
            files_created.extend([
                "sequences/X.npy (è®­ç»ƒç‰¹å¾åºåˆ—)",
                "sequences/y.npy (è®­ç»ƒç›®æ ‡)",
                "sequences/feature_names.txt (ç‰¹å¾åç§°)"
            ])
            
        print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        for f in files_created:
            print(f"  â€¢ {f}")
            
        # æ•°æ®ç»Ÿè®¡
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"  â€¢ è‚¡ç¥¨æ•°é‡: {len(symbols)}")
        print(f"  â€¢ ä»·æ ¼è®°å½•: {len(aligned_df)} æ¡")
        print(f"  â€¢ æ–°é—»è®°å½•: {len(news_df)} æ¡")
        if len(X) > 0:
            print(f"  â€¢ LSTMåºåˆ—: {X.shape[0]} ä¸ªï¼Œæ¯ä¸ªé•¿åº¦ {X.shape[1]}")
            print(f"  â€¢ ç‰¹å¾ç»´åº¦: {X.shape[2]}")
            print(f"  â€¢ ç›®æ ‡åˆ†å¸ƒ: {dict(zip(*np.unique(y, return_counts=True)))}")
        
        print(f"\nğŸ¯ ä¸‹ä¸€æ­¥: ä½¿ç”¨ç”Ÿæˆçš„åºåˆ—æ•°æ®è®­ç»ƒLSTMæ¨¡å‹")
        print("=" * 60)
        
    except Exception as e:
        print(f"âŒ æµç¨‹æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # ç¡®ä¿numpyå¯ç”¨ï¼ˆç”¨äºç»Ÿè®¡è¾“å‡ºï¼‰
    try:
        import numpy as np
    except ImportError:
        print("è­¦å‘Š: numpyæœªå®‰è£…ï¼Œéƒ¨åˆ†ç»Ÿè®¡åŠŸèƒ½ä¸å¯ç”¨")
        np = None
        
    main()